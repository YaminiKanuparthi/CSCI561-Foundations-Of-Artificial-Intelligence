{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3veDUgFO27dO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_init_prob_np(filename=\"state_weights.txt\"):\n",
        "    with open(filename, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    states = []\n",
        "    weights = []\n",
        "\n",
        "    for line in lines[2:]:\n",
        "        parts = line.strip().split()\n",
        "        states.append(parts[0].strip('\"'))\n",
        "        weights.append(int(parts[1]))\n",
        "\n",
        "    weights = np.array(weights, dtype=float)\n",
        "    weights /= weights.sum()\n",
        "\n",
        "    return dict(zip(states, weights))\n",
        "\n",
        "def get_sensor_model(filename=\"state_observation_weights.txt\", verbose=False):\n",
        "    with open(filename, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    _, _, _, default_obs_weight = map(int, lines[1].split())\n",
        "    sensor_model = {}\n",
        "    state_set = set()\n",
        "    observation_set = set()\n",
        "\n",
        "    for line in lines[2:]:\n",
        "        parts = line.strip().split()\n",
        "        state = parts[0].strip('\"')\n",
        "        observation = parts[1].strip('\"')\n",
        "        weight = int(parts[2])\n",
        "        state_set.add(state)\n",
        "        observation_set.add(observation)\n",
        "\n",
        "        # Update the state probabilities dictionary\n",
        "        if state not in sensor_model:\n",
        "            sensor_model[state] = {}\n",
        "        sensor_model[state][observation] = sensor_model[state].get(observation, 0) + weight\n",
        "\n",
        "    # Add missing states with all observations using the default weight\n",
        "    missing_states = state_set.symmetric_difference(sensor_model.keys())\n",
        "    for state in missing_states:\n",
        "        sensor_model[state] = {observation: default_obs_weight for observation in observation_set}\n",
        "\n",
        "    # Add missing observations with default weight for all states\n",
        "    for state in state_set:\n",
        "        missing_observations = observation_set.symmetric_difference(sensor_model[state].keys())\n",
        "        for observation in missing_observations:\n",
        "            sensor_model[state][observation] = default_obs_weight\n",
        "\n",
        "    # Calculate the probabilities for each state-observation pair\n",
        "    for state, obs_dict in sensor_model.items():\n",
        "        total_weight = sum(obs_dict.values())\n",
        "        for obs in obs_dict:\n",
        "            sensor_model[state][obs] = obs_dict[obs] / total_weight\n",
        "\n",
        "    if verbose:\n",
        "        for state, obs_dict in sensor_model.items():\n",
        "            print('-------------------------')\n",
        "            for obs, prob in obs_dict.items():\n",
        "                print(f'State = {state}, Obs = {obs}, Prob = {round(prob, 2)}')\n",
        "\n",
        "    return sensor_model\n",
        "\n",
        "def get_transition_model(filename=\"state_action_state_weights.txt\", verbose=False):\n",
        "    with open(filename, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    n_lines, n_states, n_actions, default_transition_weight = map(int, lines[1].split())\n",
        "\n",
        "    transition_model = {}\n",
        "    state_set = set()\n",
        "    action_set = set()\n",
        "\n",
        "    for line in lines[2:]:\n",
        "        parts = line.strip().split()\n",
        "        state = parts[0].strip('\"')\n",
        "        action = parts[1].strip('\"')\n",
        "        new_state = parts[2].strip('\"')\n",
        "        weight = int(parts[3])\n",
        "\n",
        "        state_set.add(state)\n",
        "        action_set.add(action)\n",
        "\n",
        "        if state not in transition_model:\n",
        "            transition_model[state] = {}\n",
        "        if action not in transition_model[state]:\n",
        "            transition_model[state][action] = {}\n",
        "\n",
        "        transition_model[state][action][new_state] = weight\n",
        "\n",
        "    # Add missing states, actions, and new states with default probabilities\n",
        "    for state in state_set:\n",
        "        for action in action_set:\n",
        "            if action not in transition_model[state]:\n",
        "                transition_model[state][action] = {}\n",
        "            actions = transition_model[state][action]\n",
        "            all_possible_states = set(state_set)\n",
        "            for new_state in all_possible_states:\n",
        "                if new_state not in actions:\n",
        "                    transition_model[state][action][new_state] = default_transition_weight\n",
        "\n",
        "    # Calculate the probabilities for each state-action-state pair\n",
        "    for state, action_dict in transition_model.items():\n",
        "        for action, new_state_dict in action_dict.items():\n",
        "            total_weight = sum(new_state_dict.values())\n",
        "            for new_state, weight in new_state_dict.items():\n",
        "                transition_model[state][action][new_state] = weight / total_weight\n",
        "\n",
        "    if verbose:\n",
        "        for state, action_dict in transition_model.items():\n",
        "            print('-------------------------------')\n",
        "            print(f'State = {state}')\n",
        "            for action, new_state_dict in action_dict.items():\n",
        "                print(f'\\tAction = {action}')\n",
        "                for new_state, weight in new_state_dict.items():\n",
        "                    print(f'\\t\\tState = {new_state}, Prob = {round(weight, 2)}')\n",
        "\n",
        "    return transition_model\n",
        "\n",
        "def get_observations(filename=\"observation_actions.txt\"):\n",
        "    with open(filename, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    observations = []\n",
        "\n",
        "    for i in range(2, len(lines)):\n",
        "        line = lines[i]\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) == 2:\n",
        "            state = parts[0].strip('\"')\n",
        "            action = parts[1].strip('\"')\n",
        "            observations.append((state, action))\n",
        "        else:\n",
        "            state = parts[0].strip('\"')\n",
        "            observations.append((state,))\n",
        "\n",
        "    return observations\n",
        "\n",
        "def viterbi_np(init_prob, sensor_model, transition_model, observations, verbose=False):\n",
        "    num_observations = len(observations)\n",
        "    states = list(init_prob.keys())\n",
        "    num_states = len(states)\n",
        "    state_index = {state: i for i, state in enumerate(states)}\n",
        "\n",
        "    alpha = np.zeros((num_observations, num_states))\n",
        "    backpointer = np.zeros((num_observations, num_states), dtype=int)\n",
        "\n",
        "    # Initial probabilities\n",
        "    for i, state in enumerate(states):\n",
        "        alpha[0, i] = init_prob[state] * sensor_model[state][observations[0][0]]\n",
        "\n",
        "    # Main Viterbi loop\n",
        "    for t in range(1, num_observations):\n",
        "        for i, state in enumerate(states):\n",
        "            max_prob = -1\n",
        "            best_state = 0\n",
        "            for j, prev_state in enumerate(states):\n",
        "                prob = alpha[t - 1, j] * transition_model[prev_state][observations[t - 1][1]][state] * sensor_model[state][observations[t][0]]\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    best_state = j\n",
        "            alpha[t, i] = max_prob\n",
        "            backpointer[t, i] = best_state\n",
        "\n",
        "    # Backtrack\n",
        "    most_likely_sequence = []\n",
        "    last_state = np.argmax(alpha[-1, :])\n",
        "    most_likely_sequence.append(states[last_state])\n",
        "\n",
        "    for t in range(num_observations - 1, 0, -1):\n",
        "        last_state = backpointer[t, last_state]\n",
        "        most_likely_sequence.insert(0, states[last_state])\n",
        "\n",
        "    return most_likely_sequence\n",
        "\n",
        "# Main script\n",
        "init_prob = get_init_prob_np(\"state_weights.txt\")\n",
        "sensor_model = get_sensor_model(\"state_observation_weights.txt\", verbose=False)\n",
        "transition_model = get_transition_model(\"state_action_state_weights.txt\", verbose=False)\n",
        "observations = get_observations(\"observation_actions.txt\")\n",
        "\n",
        "result = viterbi_np(init_prob, sensor_model, transition_model, observations, verbose=False)\n",
        "\n",
        "with open('states.txt', 'w') as f:\n",
        "    f.write('states\\n')\n",
        "    f.write(str(len(result))+\"\\n\")\n",
        "    for i in result:\n",
        "        f.write(f\"\\\"{i}\\\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fl9wGMIL3Wq6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}